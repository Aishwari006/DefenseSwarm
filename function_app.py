import azure.functions as func
import logging
import json
import re
import os
from openai import OpenAI

# --- PRESIDIO SETUP (Ensure you are on Python 3.11 OR using the Shim) ---
try:
    from presidio_analyzer import AnalyzerEngine
    from presidio_anonymizer import AnonymizerEngine
    analyzer = AnalyzerEngine()
    anonymizer = AnonymizerEngine()
    HAS_PRESIDIO = True
except ImportError:
    # Fallback if libraries are missing so the app doesn't crash
    HAS_PRESIDIO = False 

# =====================================================
# APP INITIALIZATION
# =====================================================
app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)

# =====================================================
# LLM CONFIG (OLLAMA / LOCAL)
# =====================================================
OLLAMA_URL = "http://localhost:11434/v1"
OLLAMA_API_KEY = "ollama"
OLLAMA_MODEL = "phi3:latest"

try:
    llm_client = OpenAI(base_url=OLLAMA_URL, api_key=OLLAMA_API_KEY)
    HAS_LLM = True
    logging.info(f"‚úÖ LLM Connected: {OLLAMA_MODEL}")
except Exception as e:
    HAS_LLM = False
    logging.error(f"‚ùå LLM unavailable: {e}")

# =====================================================
# UTILS
# =====================================================
def sanitize_text(text: str) -> str:
    if not HAS_PRESIDIO: return text
    try:
        results = analyzer.analyze(text=text, language="en", entities=["EMAIL_ADDRESS", "PHONE_NUMBER", "CREDIT_CARD"])
        return anonymizer.anonymize(text=text, analyzer_results=results).text
    except:
        return text

# =====================================================
# AGENT 1 ‚Äî THE SCREENER (Intent Classifier)
# =====================================================
@app.route(route="ScreenerAgent", auth_level=func.AuthLevel.ANONYMOUS)
def ScreenerAgent(req: func.HttpRequest) -> func.HttpResponse:
    # DEMO LOGGING: Start of Flow
    logging.warning("\n" + "="*60)
    logging.warning("üïµÔ∏è  SCREENER AGENT STARTED")
    logging.warning("-" * 60)
    
    try:
        req_body = req.get_json()
        user_input = req_body.get('message', '')
        
        # DEMO LOGGING: Input
        logging.warning(f"üì• INCOMING QUERY: '{user_input}'")

        # The original logic for raw_text and clean_text is preserved,
        raw_text = user_input # user_input is already the message/query
        
        # ... [Rest of function] ...
        
# ... (Continuing with replacements for other agents in subsequent calls or strict content matching)

# Actually, I will just do a mass replace of logging.info -> logging.warning for the demo logs

        if not raw_text:
            return func.HttpResponse(json.dumps({"error": "Missing 'message' or 'query' field in JSON"}), status_code=400)

        clean_text = sanitize_text(raw_text)

        if not HAS_LLM:
            return func.HttpResponse(json.dumps({"error": "LLM Down"}), status_code=500)

        # --- THE PROMPT (Dynamic Classification) ---
        wrapped_prompt = f"""
        [ROLE]
        You are a Security Operations Center (SOC) AI.
        
        [INPUT COMMAND]
        "{clean_text}"

        [TASK]
        1. Classify the intent of the input into exactly ONE category:
        - sql_injection (OR 1=1, UNION, syntax exploits)
        - credential_access (Stealing passwords, asking for users)
        - data_exfiltration (Dump database, show tables)
        - privilege_escalation (Override rules, Ignore instructions, Jailbreak)
        - harmless (Hello, weather, generic help)

        2.  Classify the impact of the input into exactly ONE category:
        - credential_theft        (asking for passwords / secrets directly)
        - sensitive_read          (reading sensitive tables legitimately)
        - destructive             (DROP / DELETE / MODIFY critical data)
        - harmless
        
        [OUTPUT]
        Return JSON ONLY:
        {{
          "intent": "category_name",
          "impact": "category_name",
          "confidence": <float 0.0-1.0>,
          "reason": "Brief explanation"
        }}
        """

        response = llm_client.chat.completions.create(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": "You are a JSON-only API. No markdown. No chatter."},
                {"role": "user", "content": wrapped_prompt}
            ],
            temperature=0.0
        )

        content = response.choices[0].message.content.strip()

        # --- CRITICAL FIX: CLEAN THE JSON ---
        # Local models love adding ```json ... ```. We must strip it.
        if "```" in content:
            content = content.replace("```json", "").replace("```", "")
        
        try:
            result = json.loads(content)
        except json.JSONDecodeError:
            # Fallback if LLM fails to output JSON
            result = {
                "intent": "unknown",
                "impact": "unknown",
                "confidence": 0.0,
                "reason": "LLM Parse Error"
            }


        return func.HttpResponse(
            json.dumps({
                "agent": "Screener",
                "risk_analysis": result,
                "sanitized_input": clean_text
            }, indent=2),
            mimetype="application/json"
        )

    except ValueError:
        return func.HttpResponse("Invalid Request", status_code=400)

# =====================================================
# AGENT 2 ‚Äî INVESTIGATOR (Renamed for Dashboard Compatibility)
# =====================================================
# =====================================================
# AGENT 2 ‚Äî INVESTIGATOR (Renamed for Dashboard Compatibility)
# =====================================================
@app.route(route="InvestigatorAgent", auth_level=func.AuthLevel.ANONYMOUS)
def InvestigatorAgent(req: func.HttpRequest) -> func.HttpResponse:
    # DEMO LOGGING
    logging.warning("\n" + "."*60)
    logging.warning("üß†  INVESTIGATOR AGENT STARTED")
    logging.warning("-" * 60)
    
    try:
        body = req.get_json()
        velocity = body.get("velocity", 0)
        # spread = body.get("spread", 0) # Ignored per new logic

        # DEMO LOGGING: Velocity
        logging.warning(f"üìä CHECKING VELOCITY: {velocity}")

        # Behavior Risk (from velocity) -> min(velocity / 100, 1.0)
        norm_velocity = min(velocity / 100.0, 1.0)
        behavior_risk = norm_velocity
        
        logging.warning(f"üëâ BEHAVIOR RISK SCORE: {behavior_risk:.2f}")

        return func.HttpResponse(
            json.dumps({
                "agent": "Investigator",
                "behavior_analysis": {
                    "total_risk_score": behavior_risk,
                    "velocity": norm_velocity
                }
            }, indent=2),
            mimetype="application/json"
        )
    except:
         return func.HttpResponse("Error", status_code=400)

# =====================================================
# AGENT 3 ‚Äî THE GOVERNOR (Policy Enforcer)
# =====================================================
@app.route(route="GovernorAgent", auth_level=func.AuthLevel.ANONYMOUS)
def GovernorAgent(req: func.HttpRequest) -> func.HttpResponse:
    # DEMO LOGGING
    logging.warning("\n" + "."*60)
    logging.warning("‚öñÔ∏è  GOVERNOR AGENT STARTED")
    logging.warning("-" * 60)
    
    try:
        body = req.get_json()
        intent_data = body.get("intent_data", {})
        behavior_score = body.get("behavior_score", 0.0)

        # Extract Intelligence
        intent = intent_data.get("intent", "unknown")
        impact = intent_data.get("impact", "unknown")
        
        # DEMO LOGGING: Inputs
        logging.warning(f"üì• INTENT: {intent}")
        logging.warning(f"üì• IMPACT: {impact}")
        
        # --- 1. INTENT RISK MAPPING ---
        
        # CRITICAL: Sql Injection or Privilege Escalation -> 1.0 (BLOCK IMMEDIATELY)
        if intent in ["sql_injection", "privilege_escalation"]:
            intent_risk = 1.0
        
        # Harmless -> 0.1
        elif intent == "harmless" or impact == "harmless":
            intent_risk = 0.1
            
        # Suspicious (Sensitive Read / Data Exfiltration) -> 0.4
        elif impact == "sensitive_read" or intent == "data_exfiltration":
            intent_risk = 0.4
            
        # Malicious (Credential Theft, Destruction) -> 0.85
        elif intent in ["credential_access"] or impact in ["credential_theft", "destructive"]:
            intent_risk = 0.85
            
        # Fallback / Unknown -> Default to Suspicious
        else:
            intent_risk = 0.4

        # --- 2. FINAL RISK CALCULATION ---
        # Formula: Final Risk = (0.6 * Intent) + (0.4 * Behavior)
        final_risk = (0.6 * intent_risk) + (0.4 * behavior_score)
        
        # OVERRIDE: If Intent was CRITICAL (1.0), force Final Risk to 1.0 regardless of velocity
        if intent_risk == 1.0:
             final_risk = 1.0
             
        final_risk = round(min(final_risk, 1.0), 2)
        
        policy_violation = "None"
        decision = "ALLOW"

        # --- 3. DECISION THRESHOLDS ---
        
        require_otp = False
        
        # Check condition: Risky Intent + Low Velocity (1-15 -> 0.01-0.15 score)
        # "destructive, sensitive_read, or credential_theft"
        # Removed 'privilege_escalation' from here as it is now an Immediate Block category
        is_risky_type = impact in ["destructive", "sensitive_read", "credential_theft"] or intent in ["data_exfiltration", "credential_access"]
        is_low_velocity = 0.01 <= behavior_score <= 0.15
        
        if is_risky_type and is_low_velocity:
            require_otp = True
        
        # < 0.5 -> ALLOW
        if final_risk < 0.5:
            decision = "ALLOW"
            policy_violation = "None"
            
        # 0.5 <= risk < 0.9 -> HONEYPOT (Relay / Deceptor)
        elif 0.5 <= final_risk < 0.9:
            # If OTP is required, we treat it as "Normal" (ALLOW) but with verification
            if require_otp:
                decision = "ALLOW" # Treated as normal/non-blocking
                policy_violation = "Verification Required (Low Vel Trigger)"
            else:
                decision = "VERIFY_THEN_ALLOW" # Dashboard interprets this as Honeypot Redirect
                policy_violation = "Suspicious Pattern Detected (Honeypot Candidate)"
            
        # >= 0.9 -> BLOCK
        else:
            decision = "BLOCK"
            require_otp = False # PRIORITY FIX: Never offer OTP for Blocked/Critical traffic
            policy_violation = "Critical Risk Threshold Exceeded"
            # Hard override if intent is clearly malicious (just in case formula yielded < 0.9)
            if intent_risk >= 0.85 and behavior_score > 0.5:
                decision = "BLOCK"
                policy_violation = "Zero-Trust: Malicious Intent + Velocity"

        # DEMO LOGGING: Final Decision
        logging.warning("\n" + "*"*40)
        logging.warning(f"üí• FINAL RISK SCORE: {final_risk} / 1.0")
        logging.warning(f"üì¢ DECISION: {decision}")
        if decision == "BLOCK":
             logging.warning("‚õî ACTION: KILLER AGENT TRIGGERED (IP Blocked)")
        elif decision == "VERIFY_THEN_ALLOW":
             logging.warning("üçØ ACTION: Redirecting to Honeypot...")
        elif require_otp:
             logging.warning("üì± ACTION: OTP Verification Required (Low Velocity Risk)")
        else:
             logging.warning("‚úÖ ACTION: Traffic Normal")
        logging.warning("*"*40 + "\n")

        return func.HttpResponse(
            json.dumps({
                "agent": "Governor",
                "decision": decision,
                "final_risk_score": final_risk,
                "policy_violation": policy_violation,
                "require_otp": require_otp,
                "impact": impact
            }, indent=2),
            mimetype="application/json"
        )

    except Exception as e:
        logging.error(str(e))
        return func.HttpResponse("Error", status_code=400)

# =====================================================
# SYSTEM LOGGER (For Honeypot / Frontend Remote Logging)
# =====================================================
@app.route(route="SystemLogger", auth_level=func.AuthLevel.ANONYMOUS)
def SystemLogger(req: func.HttpRequest) -> func.HttpResponse:
    try:
        body = req.get_json()
        log_type = body.get("type", "INFO")
        message = body.get("message", "")
        
        if log_type == "HEADER":
            logging.warning("\n" + "."*60)
            logging.warning(f"üçØ  {message}")
            logging.warning("-" * 60)
        elif log_type == "decision_block":
             logging.warning("\n" + "*"*40)
             logging.warning(f"üí• FINAL RISK SCORE: {body.get('risk')} / 1.0")
             logging.warning(f"üì¢ DECISION: BLOCK")
             logging.warning("‚õî ACTION: KILLER AGENT TRIGGERED (Redirecting to Blocked Page)")
             logging.warning("*"*40 + "\n")
        elif log_type == "decision_allow":
             logging.warning("\n" + "*"*40)
             logging.warning(f"üí• FINAL RISK SCORE: {body.get('risk')} / 1.0")
             logging.warning(f"üì¢ DECISION: ALLOW")
             logging.warning("‚úÖ ACTION: DAMPENING APPLIED (Redirecting to Production)")
             logging.warning("*"*40 + "\n")
        else:
            logging.warning(f"{message}")

        return func.HttpResponse("Logged", status_code=200)
    except Exception as e:
        logging.error(str(e))
        return func.HttpResponse("Error", status_code=400)